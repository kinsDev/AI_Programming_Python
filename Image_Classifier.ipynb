{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing pytorch and other related libraries that will be required in this project\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "from collections import OrderedDict\n",
    "#import random, os\n",
    "import time\n",
    "\n",
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "data_dir = 'flowers'\n",
    "train_dir = data_dir + '/train'\n",
    "valid_dir = data_dir + '/valid'\n",
    "test_dir = data_dir + '/test'\n",
    "\n",
    "# TODO: Define your transforms for the training, validation, and testing sets\n",
    "training_transformations = transforms.Compose([transforms.RandomRotation(30),\n",
    "                                               transforms.RandomResizedCrop(224),\n",
    "                                               transforms.RandomHorizontalFlip(),\n",
    "                                               transforms.ToTensor(),\n",
    "                                               transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                                    [0.229, 0.224, 0.225])])\n",
    "\n",
    "testing_transformations = transforms.Compose([transforms.Resize(256),\n",
    "                                              transforms.CenterCrop(224),\n",
    "                                              transforms.ToTensor(),\n",
    "                                              transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                                   [0.229, 0.224, 0.225])])\n",
    "\n",
    "validation_transformations = transforms.Compose([transforms.Resize(256),\n",
    "                                                 transforms.CenterCrop(224),\n",
    "                                                 transforms.ToTensor(),\n",
    "                                                 transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                                      [0.229, 0.224, 0.225])])\n",
    "\n",
    "# TODO: Load the datasets with ImageFolder\n",
    "training_dataset = datasets.ImageFolder(train_dir, transform=training_transformations)\n",
    "validation_dataset = datasets.ImageFolder(valid_dir, transform=validation_transformations)\n",
    "testing_dataset = datasets.ImageFolder(test_dir, transform=testing_transformations)\n",
    "\n",
    "# TODO: Using the image datasets and the trainforms, define the dataloaders\n",
    "training_loader = torch.utils.data.DataLoader(training_dataset, batch_size=64, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=64, shuffle=True)\n",
    "testing_loader = torch.utils.data.DataLoader(testing_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "\n",
    "with open('cat_to_name.json', 'r') as f:\n",
    "    cat_to_name = json.load(f)\n",
    "\n",
    "# Load a pretrained network\n",
    "# According to the guidelines: The VGG network is easier to use\n",
    "model = models.vgg16(pretrained = True)\n",
    "model\n",
    "\n",
    "# Freeze model parameters to avoid backpropagation\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Since I have been offered GPU for a plenty amount of time\n",
    "# I'll define my device as CUDA to leverage the GPU power\n",
    "device = torch.device('cuda')\n",
    "\n",
    "# Define a new, untrained feed-forward network as a classifier, using ReLU activations and dropout\n",
    "classifier = nn.Sequential(OrderedDict([\n",
    "    ('dropout', nn.Dropout(0.2)),\n",
    "    ('fc1', nn.Linear(25088, 512)),\n",
    "    ('relu1', nn.ReLU()),\n",
    "    ('fc2', nn.Linear(512, 256)),\n",
    "    ('relu2', nn.ReLU()),\n",
    "    ('fc3', nn.Linear(256, 128)),\n",
    "    ('relu3', nn.ReLU()),\n",
    "    ('output', nn.Linear(128, 102)),\n",
    "    ('log_softmax', nn.LogSoftmax(dim=1))\n",
    "]))\n",
    "\n",
    "model.classifier = classifier\n",
    "model\n",
    "\n",
    "# At this point, I'm going to move my model to CUDA so that it can train using GPU\n",
    "model = model.to(device)\n",
    "\n",
    "# Define loss function, learning rate, optimizer, epochs, print_every, steps\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)\n",
    "epochs = 5\n",
    "print_every = 10\n",
    "steps = 0\n",
    "\n",
    "training_losses = []\n",
    "validation_losses = []\n",
    "\n",
    "print('Training has started')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0\n",
    "\n",
    "    for ii, (training_images, training_labels) in enumerate(training_loader):\n",
    "        # Increase the steps by 1\n",
    "        steps += 1\n",
    "\n",
    "        # get data(images and labels) to GPU, since I have it available\n",
    "        training_images, training_labels = training_images.to(device), training_labels.to(device)\n",
    "\n",
    "        # Setting all gradients for each batch to 0\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward passes\n",
    "        outputs = model.forward(training_images)\n",
    "        loss = criterion(outputs, training_labels)\n",
    "\n",
    "        # Backward passes\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        training_losses.append((running_loss / len(training_loader)))\n",
    "\n",
    "        if steps % print_every == 0:\n",
    "            model.eval()\n",
    "            validation_loss = 0\n",
    "            accuracy = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for ii, (validation_images, validation_labels) in enumerate(validation_loader):\n",
    "                    validation_images, validation_labels = validation_images.to(device), validation_labels.to(device)\n",
    "                    log_ps = model(validation_images)\n",
    "                    loss = criterion(log_ps, validation_labels)\n",
    "                    validation_loss += loss.item()\n",
    "\n",
    "                    ps = torch.exp(log_ps)\n",
    "                    top_p, top_class = ps.topk(1, dim=1)\n",
    "                    equality = top_class == validation_labels.view(*top_class.shape)\n",
    "                    accuracy += torch.mean(equality.type(torch.FloatTensor)).item()\n",
    "\n",
    "            # Calculating the average validation loss and accuracy\n",
    "            validation_loss /= len(validation_loader)\n",
    "            accuracy /= len(validation_loader)\n",
    "\n",
    "            print(f\"Epoch: {epoch+1}/{epochs}.. \"\n",
    "                  f\"Train loss: {running_loss/len(training_loader):.3f}.. \"\n",
    "                  f\"Test loss: {validation_loss:.3f}.. \"\n",
    "                  f\"Test accuracy: {accuracy:.3f}\")\n",
    "            running_loss = 0\n",
    "            model.train()\n",
    "print(\"\\nTraining has ended:)\")\n",
    "\n",
    "# TODO: Do validation on the test set\n",
    "\n",
    "accuracy = 0\n",
    "print(\"Testing has started...\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for ii, (testing_images, testing_labels) in enumerate(testing_loader):\n",
    "        testing_images, testing_labels = testing_images.to(device), testing_labels.to(device)\n",
    "        log_ps = model(testing_images)\n",
    "\n",
    "        ps = torch.exp(log_ps)\n",
    "        top_p, top_class = ps.topk(1, dim=1)\n",
    "        equality = top_class == testing_labels.view(*top_class.shape)\n",
    "        accuracy += torch.mean(equality.type(torch.FloatTensor)).item()\n",
    "\n",
    "accuracy /= len(testing_loader) * 100\n",
    "\n",
    "print(f\"After testing, the accuracy of model is: {accuracy:.3f}%\")\n",
    "print(\"Testing has ended!\")\n",
    "\n",
    "# Displaying the training and validation loss on a plot\n",
    "plt.plot(training_losses, label='Training loss')\n",
    "plt.plot(validation_losses, label='Testing loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend();\n",
    "plt.show()\n",
    "\n",
    "# TODO: Save the checkpoint \n",
    "checkpoint = {\n",
    "    'input_size': 25088,\n",
    "    'output_size': 102,\n",
    "    'hidden_size': [512, 256, 128],\n",
    "    'dropout': 0.2,\n",
    "    'learning_rate': 0.001,\n",
    "    'model_architecture': 'vgg16',\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'class_to_idx': training_dataset.class_to_idx,\n",
    "    'epochs': epochs,\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "}\n",
    "torch.save(checkpoint, 'checkpoint.pth')\n",
    "\n",
    "# TODO: Write a function that loads a checkpoint and rebuilds the model\n",
    "def load_checkpoint(pth_fname):\n",
    "    checkpoint = torch.load(pth_fname)\n",
    "    model_architecture = checkpoint['model_architecture']\n",
    "\n",
    "    # Loading pretrained model\n",
    "    model = getattr(models, model_architecture)(pretrained=False)\n",
    "\n",
    "    # Loading the classifier and model state_dict\n",
    "    model.classifier = checkpoint['classifier']\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    # Initializing the optimizer with the correct learning rate and loading the optimizer state_dict\n",
    "    optimizer = optim.Adam(model.classifier.parameters(), lr=checkpoint['learning_rate'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "    # Checkpoint values\n",
    "    input_size = checkpoint['input_size']\n",
    "    hidden_size = checkpoint['hidden_size']\n",
    "    output_size = checkpoint['output_size']\n",
    "    class_to_idx = checkpoint['class_to_idx']\n",
    "    epochs = checkpoint['epochs']\n",
    "\n",
    "    return model, optimizer, input_size, hidden_size, output_size, class_to_idx, epochs\n",
    "\n",
    "# Load the checkpoint\n",
    "model, optimizer, input_size, hidden_size, output_size, class_to_idx, epochs = load_checkpoint('checkpoint.pth')\n",
    "\n",
    "def process_image(image):\n",
    "    ''' Scales, crops, and normalizes a PIL image for a PyTorch model,\n",
    "        returns an Numpy array\n",
    "    '''\n",
    "\n",
    "    # TODO: Process a PIL image for use in a PyTorch model\n",
    "    # Defining transfomations to resize, crop out the center, normalize, and converting the image to a pytorch tensor \n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    image = preprocess(image)\n",
    "    return image\n",
    "\n",
    "def imshow(image, ax=None, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "    # PyTorch tensors assume the color channel is the first dimension\n",
    "    # but matplotlib assumes is the third dimension\n",
    "    image = image.numpy().transpose((1, 2, 0))\n",
    "\n",
    "    # Undo preprocessing\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    image = std * image + mean\n",
    "\n",
    "    # Image needs to be clipped between 0 and 1 or it looks like noise when displayed\n",
    "    image = np.clip(image, 0, 1)\n",
    "\n",
    "    ax.imshow(image)\n",
    "\n",
    "    return ax\n",
    "\n",
    "image_path = 'flowers/test/100/image_07902.jpg'\n",
    "\n",
    "# Display original image\n",
    "with Image.open(image_path) as image:\n",
    "    plt.imshow(image)\n",
    "    plt.title('Original Image')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Display preprocessed image\n",
    "with Image.open(image_path) as image:\n",
    "    processed_image = process_image(image)\n",
    "    imshow(processed_image, title='Processed Image')\n",
    "    plt.show()\n",
    "\n",
    "def predict(image_path, model, topk=5):\n",
    "    ''' Predict the class (or classes) of an image using a trained deep learning model.\n",
    "    '''\n",
    "    # TODO: Implement the code to predict the class from an image file\n",
    "\n",
    "    # Preprocess the image\n",
    "    # adding batch dimension since networks take input as batches\n",
    "    # https://pytorch.org/docs/stable/tensors.html#torch.Tensor\n",
    "    img_tensor = process_image(image_path).unsqueeze(0).to(device)\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        output = model(img_tensor)\n",
    "        probabilities, indices = torch.topk(torch.exp(output), topk)\n",
    "\n",
    "    # Convert indices to class labels\n",
    "    idx_to_class = {val: key for key, val in model.class_to_idx.items()}\n",
    "    classes = [idx_to_class[idx.item()] for idx in indices[0]]\n",
    "\n",
    "    return probabilities, classes\n",
    "\n",
    "image_path = 'flowers/test/101/image_07952.jpg'\n",
    "probs, classes = predict(image_path, model)\n",
    "print(probs)\n",
    "print(classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
